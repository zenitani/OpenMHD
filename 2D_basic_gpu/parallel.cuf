module parallel
  use cudafor
  use mpi
  implicit none

  ! 2-D domain
  integer, parameter :: ndims = 2

  ! topology
  type mycoords
     integer :: comm
     integer :: sizes(ndims)
     integer :: coords(ndims)
     logical :: periods(ndims)
  end type mycoords
  type(mycoords) :: cart2d

  ! rank info
  type myranks
     integer :: size = 0
     integer :: myrank
     integer :: north, east, south, west
  end type myranks

  type(myranks) :: ranks         ! global communication
  type(myranks) :: ranks_local   ! intra-node communication
  integer, private :: comm_local ! intra-node communication

  ! ----- MPI-3 shared memory communication ------------------------
  logical, parameter, private :: use_shm = .false.  ! MPI communication
! logical, parameter, private :: use_shm = .true.   ! MPI-3 SHM model (experimental)
  integer(kind=cuda_stream_kind), private :: comm_stream

! Please do not edit here
  integer, private :: mpi_mode(ndims) = (/1, 1/)  ! 0: no MPI, 1: MPI-1, 3: MPI-3
  integer, private :: mwin1, mwin2
  real(8), private, dimension(:,:,:), pointer, contiguous :: fptr1 => null()
  real(8), private, dimension(:,:,:), pointer, contiguous :: fwest => null()
  real(8), private, dimension(:,:,:), pointer, contiguous :: feast => null()
  real(8), private, dimension(:,:,:), pointer, contiguous :: fptr2  => null()
  real(8), private, dimension(:,:,:), pointer, contiguous :: fsouth => null()
  real(8), private, dimension(:,:,:), pointer, contiguous :: fnorth => null()
  ! ----- MPI-3 shared memory communication ------------------------

contains

  subroutine parallel_init(my_sizes,my_periods,ix,jx)
    use cudafor
    use, intrinsic :: iso_c_binding, only : c_f_pointer, c_ptr
    include 'param.h'
    integer, intent(in) :: my_sizes(ndims)
    logical, intent(in) :: my_periods(ndims)
    integer, intent(in) :: ix, jx
    integer :: i
    integer :: tmpA(4), tmpB(4)
    integer :: group_world, group_local
    integer :: mdisp, merr, merrcode
    integer(kind=mpi_address_kind) :: msize
    type(c_ptr) :: baseptr1, baseptr2
    integer :: stat

    call mpi_init(merr)

    cart2d%sizes(:) = my_sizes(:)
    cart2d%coords(:)  = 0
    cart2d%periods(:) = my_periods(:)

    ! After this, one should use cart2d%comm instead of mpi_comm_world
    call mpi_cart_create(mpi_comm_world, ndims, cart2d%sizes, cart2d%periods, .true., cart2d%comm, merr)
    call mpi_comm_size (cart2d%comm, ranks%size, merr)
    call mpi_comm_rank (cart2d%comm, ranks%myrank, merr)
    call mpi_cart_shift(cart2d%comm, 0, 1,ranks%west, ranks%east, merr)
    call mpi_cart_shift(cart2d%comm, 1, 1,ranks%south,ranks%north,merr)
    call mpi_cart_coords(cart2d%comm, ranks%myrank, 2, cart2d%coords, merr)

    if( ranks%size /= my_sizes(1)*my_sizes(2) ) then
       if( ranks%myrank == 0 ) then
          write(6,*) 'MPI process numbers mismatch.'
       endif
       merrcode = -1
       call mpi_abort(cart2d%comm, merrcode, merr)
    endif

    ! MPI mode
    ! No MPI transport in the case of 1
    if( cart2d%sizes(1) == 1 )  mpi_mode(1) = 0
    if( cart2d%sizes(2) == 1 )  mpi_mode(2) = 0

    stat = cudaStreamCreate(comm_stream)

    ! ----- MPI-3 shared memory communication ------------------------
    if( use_shm ) then

       ! node-local mapping
       tmpA = (/ranks%north, ranks%east, ranks%south, ranks%west/)
       call mpi_comm_split_type(cart2d%comm, mpi_comm_type_shared, 0, mpi_info_null, comm_local, merr)
       call mpi_comm_group(cart2d%comm, group_world, merr)
       call mpi_comm_group(comm_local,  group_local, merr)
       call mpi_group_translate_ranks(group_world, 4, tmpA, group_local, tmpB, merr)
       call mpi_comm_size(comm_local, ranks_local%size, merr)
       call mpi_comm_rank(comm_local, ranks_local%myrank, merr)
       do i=1,4
          if( tmpB(i) == mpi_proc_null )  tmpB(i) = mpi_undefined
       enddo
       ranks_local%north = tmpB(1) ;   ranks_local%east = tmpB(2)
       ranks_local%south = tmpB(3) ;   ranks_local%west = tmpB(4)

       ! preparing shared memories for west <--> east communication
       if(( ranks_local%size > 1 ).and.( mpi_mode(1) == 1 )) then

          ! NOTE: This value should be shared in the local node, because
          ! the local mpi_barrier is critical in the communication part.
          mpi_mode(1) = 3

          if(( ranks_local%west /= mpi_undefined ).or.( ranks_local%east /= mpi_undefined )) then
             msize = 2*8*jx*var1
             mdisp = 0
             call mpi_win_allocate_shared(msize,8,mpi_info_null,comm_local,baseptr1,mwin1,merr)
             call c_f_pointer(baseptr1,fptr1,(/jx,var1,2/))
             if( ranks_local%west /= mpi_undefined ) then
                call mpi_win_shared_query(mwin1,ranks_local%west,msize,mdisp,baseptr1,merr)
                call c_f_pointer(baseptr1,fwest,(/jx,var1,2/))
             endif
             if( ranks_local%east /= mpi_undefined ) then
                call mpi_win_shared_query(mwin1,ranks_local%east,msize,mdisp,baseptr1,merr)
                call c_f_pointer(baseptr1,feast,(/jx,var1,2/))
             endif
          else
             ! dummy pointer
             msize = 0
             call mpi_win_allocate_shared(msize,8,mpi_info_null,comm_local,baseptr1,mwin1,merr)
          endif

       endif

       ! preparing shared memories for south <--> north communication
       if(( ranks_local%size > 1 ).and.( mpi_mode(2) == 1 )) then

          ! NOTE: This value should be shared in the local node, because
          ! the local mpi_barrier is critical in the communication part.
          mpi_mode(2) = 3

          if(( ranks_local%north /= mpi_undefined ).or.( ranks_local%south /= mpi_undefined )) then
             msize = 2*8*ix*var1
             mdisp = 0
             call mpi_win_allocate_shared(msize,8,mpi_info_null,comm_local,baseptr2,mwin2,merr)
             call c_f_pointer(baseptr2,fptr2,(/ix,var1,2/))
             if( ranks_local%south /= mpi_undefined ) then
                call mpi_win_shared_query(mwin2,ranks_local%south,msize,mdisp,baseptr2,merr)
                call c_f_pointer(baseptr2,fsouth,(/ix,var1,2/))
             endif
             if( ranks_local%north /= mpi_undefined ) then
                call mpi_win_shared_query(mwin2,ranks_local%north,msize,mdisp,baseptr2,merr)
                call c_f_pointer(baseptr2,fnorth,(/ix,var1,2/))
             endif
          else
             ! dummy pointer
             msize = 0
             call mpi_win_allocate_shared(msize,8,mpi_info_null,comm_local,baseptr2,mwin2,merr)
          endif

       endif

    endif
    ! ----- MPI-3 shared memory communication ------------------------

    return
  end subroutine parallel_init


  subroutine parallel_finalize
    use cudafor
    integer :: merr
    integer :: stat

    stat = cudaStreamDestroy(comm_stream)
    if( mpi_mode(1) == 3 )  call mpi_win_free(mwin1,merr)
    if( mpi_mode(2) == 3 )  call mpi_win_free(mwin2,merr)
    call mpi_finalize(merr)
  
  end subroutine parallel_finalize


  attributes(host) &
  subroutine parallel_exchange(Ud,ix,jx,dir)
    use cudafor
    include 'param.h'
    integer, intent(in) :: ix, jx
    real(8), device, intent(inout) :: Ud(ix,jx,var1)
    ! direction [input]: 1 (X), 2 (Y), 3 (Z)
    integer, intent(in) :: dir
!----------------------------------------------------------------------
    real(8), device, allocatable :: bufsnd1(:,:), bufrcv1(:,:)
    real(8), device, allocatable :: bufsnd2(:,:), bufrcv2(:,:)
    integer :: mreq1(2), mreq2(2)
    integer :: msize, merr
    integer :: i,j,k
    integer :: stat
!----------------------------------------------------------------------

    select case(dir)
    case(1)  ! west <--> east

       allocate( bufsnd1(jx,var1), bufrcv1(jx,var1) )
       allocate( bufsnd2(jx,var1), bufrcv2(jx,var1) )
       msize  = jx*var1

       ! MPI mode switch
       select case(mpi_mode(1))
       case(0)  ! no MPI

          ! periodic
          if( ranks%west /= mpi_proc_null ) then
             !$cuf kernel do(2) <<<*, *, stream=comm_stream>>>
             do k=1,var1; do j=1,jx
                Ud( 1,j,k) = Ud(ix-1,j,k)
                Ud(ix,j,k) = Ud(   2,j,k)
             enddo; enddo
          endif

       case(1)  ! MPI-1

          ! nonblocking communication (mreq1)
          call mpi_irecv(bufrcv1,msize,mpi_real8,ranks%east,0,cart2d%comm,mreq1(1),merr)
          !$cuf kernel do(2) <<<*, *, stream=comm_stream>>>
          do k=1,var1; do j=1,jx
             bufsnd1(j,k) = Ud(2,j,k)
          enddo; enddo
          stat = cudaStreamSynchronize(comm_stream)
          call mpi_isend(bufsnd1,msize,mpi_real8,ranks%west,0,cart2d%comm,mreq1(2),merr)
          ! nonblocking communication (mreq2)
          call mpi_irecv(bufrcv2,msize,mpi_real8,ranks%west,1,cart2d%comm,mreq2(1),merr)
          !$cuf kernel do(2) <<<*, *, stream=comm_stream>>>
          do k=1,var1; do j=1,jx
             bufsnd2(j,k) = Ud(ix-1,j,k)
          enddo; enddo
          stat = cudaStreamSynchronize(comm_stream)
          call mpi_isend(bufsnd2,msize,mpi_real8,ranks%east,1,cart2d%comm,mreq2(2),merr)

          call mpi_waitall(2,mreq1,mpi_statuses_ignore,merr)
          if( ranks%east /= mpi_proc_null ) then
             !$cuf kernel do(2) <<<*, *, stream=comm_stream>>>
             do k=1,var1; do j=1,jx
                Ud(ix,j,k) = bufrcv1(j,k)
             enddo; enddo
          endif
          call mpi_waitall(2,mreq2,mpi_statuses_ignore,merr)
          if( ranks%west /= mpi_proc_null ) then
             !$cuf kernel do(2) <<<*, *, stream=comm_stream>>>
             do k=1,var1; do j=1,jx
                Ud(1,j,k) = bufrcv2(j,k)
             enddo; enddo
          endif

       case(3)  ! MPI-3

          call mpi_win_lock_all(0,mwin1,merr)
          !$cuf kernel do(2) <<<*, *, stream=comm_stream>>>
          do k=1,var1; do j=1,jx
             bufsnd1(j,k) = Ud(2,j,k)
          enddo; enddo
          if( ranks_local%west /= mpi_undefined ) then
             stat = cudaStreamSynchronize(comm_stream)
             fwest(:,:,2) = bufsnd1(:,:)
          else
             call mpi_irecv(bufrcv2,msize,mpi_real8,ranks%west,1,cart2d%comm,mreq1(1),merr)
             stat = cudaStreamSynchronize(comm_stream)
             call mpi_isend(bufsnd1,msize,mpi_real8,ranks%west,0,cart2d%comm,mreq1(2),merr)
          endif
          !$cuf kernel do(2) <<<*, *, stream=comm_stream>>>
          do k=1,var1; do j=1,jx
             bufsnd2(j,k) = Ud(ix-1,j,k)
          enddo; enddo
          if( ranks_local%east /= mpi_undefined ) then
             stat = cudaStreamSynchronize(comm_stream)
             feast(:,:,1) = bufsnd2(:,:)
          else
             call mpi_irecv(bufrcv1,msize,mpi_real8,ranks%east,0,cart2d%comm,mreq2(1),merr)
             stat = cudaStreamSynchronize(comm_stream)
             call mpi_isend(bufsnd2,msize,mpi_real8,ranks%east,1,cart2d%comm,mreq2(2),merr)
          endif

          call mpi_win_unlock_all(mwin1,merr)
          call mpi_barrier(comm_local,merr)  ! local barrier

          if( ranks_local%west /= mpi_undefined ) then
             bufrcv2(:,:) = fptr1(:,:,1)
             !$cuf kernel do(2) <<<*, *, stream=comm_stream>>>
             do k=1,var1; do j=1,jx
                Ud(1,j,k) = bufrcv2(j,k)
             enddo; enddo
          else
             call mpi_waitall(2,mreq1,mpi_statuses_ignore,merr)
             if( ranks%west /= mpi_proc_null ) then
                !$cuf kernel do(2) <<<*, *, stream=comm_stream>>>
                do k=1,var1; do j=1,jx
                   Ud(1,j,k) = bufrcv2(j,k)
                enddo; enddo
             endif
          endif
          if( ranks_local%east /= mpi_undefined ) then
             bufrcv1(:,:) = fptr1(:,:,2)
             !$cuf kernel do(2) <<<*, *, stream=comm_stream>>>
             do k=1,var1; do j=1,jx
                Ud(ix,j,k) = bufrcv1(j,k)
             enddo; enddo
          else
             call mpi_waitall(2,mreq2,mpi_statuses_ignore,merr)
             if( ranks%east /= mpi_proc_null ) then
                !$cuf kernel do(2) <<<*, *, stream=comm_stream>>>
                do k=1,var1; do j=1,jx
                   Ud(ix,j,k) = bufrcv1(j,k)
                enddo; enddo
             endif
          endif

       end select
       ! MPI mode switch

       stat = cudaStreamSynchronize(comm_stream)
       deallocate( bufsnd1, bufrcv1 )
       deallocate( bufsnd2, bufrcv2 )

    !----------------------------------------------------------
    case(2)  ! south <--> north

       allocate( bufsnd1(ix,var1), bufrcv1(ix,var1) )
       allocate( bufsnd2(ix,var1), bufrcv2(ix,var1) )
       msize  = ix*var1

       ! MPI mode switch
       select case(mpi_mode(2))
       case(0)  ! no MPI

          ! periodic
          if( ranks%south /= mpi_proc_null ) then
             !$cuf kernel do(2) <<<*, *, stream=comm_stream>>>
             do k=1,var1; do i=1,ix
                Ud(i,jx,k) = Ud(i,   2,k)
                Ud(i, 1,k) = Ud(i,jx-1,k)
             enddo; enddo
          endif

       case(1)  ! MPI-1

          ! nonblocking communication (mreq1)
          call mpi_irecv(bufrcv1,msize,mpi_real8,ranks%north,0,cart2d%comm,mreq1(1),merr)
          !$cuf kernel do(2) <<<*, *, stream=comm_stream>>>
          do k=1,var1; do i=1,ix
             bufsnd1(i,k) = Ud(i,2,k)
          enddo; enddo
          stat = cudaStreamSynchronize(comm_stream)
          call mpi_isend(bufsnd1,msize,mpi_real8,ranks%south,0,cart2d%comm,mreq1(2),merr)
          ! nonblocking communication (mreq2)
          call mpi_irecv(bufrcv2,msize,mpi_real8,ranks%south,1,cart2d%comm,mreq2(1),merr)
          !$cuf kernel do(2) <<<*, *, stream=comm_stream>>>
          do k=1,var1; do i=1,ix
             bufsnd2(i,k) = Ud(i,jx-1,k)
          enddo; enddo
          stat = cudaStreamSynchronize(comm_stream)
          call mpi_isend(bufsnd2,msize,mpi_real8,ranks%north,1,cart2d%comm,mreq2(2),merr)

          call mpi_waitall(2,mreq1,mpi_statuses_ignore,merr)
          if( ranks%north /= mpi_proc_null ) then
             !$cuf kernel do(2) <<<*, *, stream=comm_stream>>>
             do k=1,var1; do i=1,ix
                Ud(i,jx,k) = bufrcv1(i,k)
             enddo; enddo
          endif
          call mpi_waitall(2,mreq2,mpi_statuses_ignore,merr)
          if( ranks%south /= mpi_proc_null ) then
             !$cuf kernel do(2) <<<*, *, stream=comm_stream>>>
             do k=1,var1; do i=1,ix
                Ud(i,1,k) = bufrcv2(i,k)
             enddo; enddo
          endif

       case(3)  ! MPI-3

          call mpi_win_lock_all(0,mwin2,merr)
          !$cuf kernel do(2) <<<*, *, stream=comm_stream>>>
          do k=1,var1; do i=1,ix
             bufsnd1(i,k) = Ud(i,2,k)
          enddo; enddo
          if( ranks_local%south /= mpi_undefined ) then
             stat = cudaStreamSynchronize(comm_stream)
             fsouth(:,:,2) = bufsnd1(:,:)
          else
             call mpi_irecv(bufrcv2,msize,mpi_real8,ranks%south,1,cart2d%comm,mreq1(1),merr)
             stat = cudaStreamSynchronize(comm_stream)
             call mpi_isend(bufsnd1,msize,mpi_real8,ranks%south,0,cart2d%comm,mreq1(2),merr)
          endif
          if( ranks_local%north /= mpi_undefined ) then
             !$cuf kernel do(2) <<<*, *, stream=comm_stream>>>
             do k=1,var1; do i=1,ix
                bufsnd2(i,k) = Ud(i,jx-1,k)
             enddo; enddo
             stat = cudaStreamSynchronize(comm_stream)
             fnorth(:,:,1) = bufsnd2(:,:)
          else
             call mpi_irecv(bufrcv1,msize,mpi_real8,ranks%north,0,cart2d%comm,mreq2(1),merr)
             !$cuf kernel do(2) <<<*, *, stream=comm_stream>>>
             do k=1,var1; do i=1,ix
                bufsnd2(i,k) = Ud(i,jx-1,k)
             enddo; enddo
             stat = cudaStreamSynchronize(comm_stream)
             call mpi_isend(bufsnd2,msize,mpi_real8,ranks%north,1,cart2d%comm,mreq2(2),merr)
          endif

          call mpi_win_unlock_all(mwin2,merr)
          call mpi_barrier(comm_local,merr)  ! local barrier

          if( ranks_local%south /= mpi_undefined ) then
             bufrcv2(:,:) = fptr2(:,:,1)
             !$cuf kernel do(2) <<<*, *, stream=comm_stream>>>
             do k=1,var1; do i=1,ix
                Ud(i,1,k) = bufrcv2(i,k)
             enddo; enddo
          else
             call mpi_waitall(2,mreq1,mpi_statuses_ignore,merr)
             if( ranks%south /= mpi_proc_null ) then
                !$cuf kernel do(2) <<<*, *, stream=comm_stream>>>
                do k=1,var1; do i=1,ix
                   Ud(i,1,k) = bufrcv2(i,k)
                enddo; enddo
             endif
          endif
          if( ranks_local%north /= mpi_undefined ) then
             bufrcv1(:,:) = fptr2(:,:,2)
             !$cuf kernel do(2) <<<*, *, stream=comm_stream>>>
             do k=1,var1; do i=1,ix
                Ud(i,jx,k) = bufrcv1(i,k)
             enddo; enddo
             stat = cudaStreamSynchronize(comm_stream)
          else
             call mpi_waitall(2,mreq2,mpi_statuses_ignore,merr)
             if( ranks%north /= mpi_proc_null ) then
                !$cuf kernel do(2) <<<*, *, stream=comm_stream>>>
                do k=1,var1; do i=1,ix
                   Ud(i,jx,k) = bufrcv1(i,k)
                enddo; enddo
             endif
          endif
 
       end select
       ! MPI mode switch

       stat = cudaStreamSynchronize(comm_stream)
       deallocate( bufsnd1, bufrcv1 )
       deallocate( bufsnd2, bufrcv2 )

    end select

  end subroutine parallel_exchange


  attributes(host) &
  subroutine parallel_exchange2(VLd,VRd,ix,jx,dir)
    use cudafor
    include 'param.h'
    integer, intent(in) :: ix, jx
    real(8), device, intent(inout) :: VLd(ix,jx,var1)  ! left values (VL)
    real(8), device, intent(inout) :: VRd(ix,jx,var1)  ! right values (VR)
    ! direction [input]: 1 (X), 2 (Y), 3 (Z)
    integer, intent(in) :: dir
!----------------------------------------------------------------------
    real(8), device, allocatable :: bufsnd1(:,:), bufrcv1(:,:)
    real(8), device, allocatable :: bufsnd2(:,:), bufrcv2(:,:)
    integer :: mreq1(2), mreq2(2)
    integer :: msize, merr
    integer :: i,j,k
    integer :: stat
!----------------------------------------------------------------------

    select case(dir)
    case(1)  ! west <--> east

       allocate( bufsnd1(jx,var1), bufrcv1(jx,var1) )
       allocate( bufsnd2(jx,var1), bufrcv2(jx,var1) )
       msize  = jx*var1

       ! MPI mode switch
       select case(mpi_mode(1))
       case(0)  ! no MPI

          ! periodic
          if( ranks%west /= mpi_proc_null ) then
             !$cuf kernel do(2) <<<*, *, stream=comm_stream>>>
             do k=1,var1; do j=1,jx
                VRd(ix-1,j,k) = VRd(   1,j,k)
                VLd(   1,j,k) = VLd(ix-1,j,k)
             enddo; enddo
          endif

       case(1)  ! MPI-1

          ! nonblocking communication (mreq1)
          call mpi_irecv(bufrcv1,msize,mpi_real8,ranks%east,0,cart2d%comm,mreq1(1),merr)
          !$cuf kernel do(2) <<<*, *, stream=comm_stream>>>
          do k=1,var1; do j=1,jx
             bufsnd1(j,k) = VRd(1,j,k)
          enddo; enddo
          stat = cudaStreamSynchronize(comm_stream)
          call mpi_isend(bufsnd1,msize,mpi_real8,ranks%west,0,cart2d%comm,mreq1(2),merr)
          ! nonblocking communication (mreq2)
          call mpi_irecv(bufrcv2,msize,mpi_real8,ranks%west,1,cart2d%comm,mreq2(1),merr)
          !$cuf kernel do(2) <<<*, *, stream=comm_stream>>>
          do k=1,var1; do j=1,jx
             bufsnd2(j,k) = VLd(ix-1,j,k)
          enddo; enddo
          stat = cudaStreamSynchronize(comm_stream)
          call mpi_isend(bufsnd2,msize,mpi_real8,ranks%east,1,cart2d%comm,mreq2(2),merr)

          call mpi_waitall(2,mreq1,mpi_statuses_ignore,merr)
          if( ranks%east /= mpi_proc_null ) then
             !$cuf kernel do(2) <<<*, *, stream=comm_stream>>>
             do k=1,var1; do j=1,jx
                VRd(ix-1,j,k) = bufrcv1(j,k)
             enddo; enddo
          endif
          call mpi_waitall(2,mreq2,mpi_statuses_ignore,merr)
          if( ranks%west /= mpi_proc_null ) then
             !$cuf kernel do(2) <<<*, *, stream=comm_stream>>>
             do k=1,var1; do j=1,jx
                VLd(1,j,k) = bufrcv2(j,k)
             enddo; enddo
          endif

       case(3)  ! MPI-3

          call mpi_win_lock_all(0,mwin1,merr)
          !$cuf kernel do(2) <<<*, *, stream=comm_stream>>>
          do k=1,var1; do j=1,jx
             bufsnd1(j,k) = VRd(1,j,k)
          enddo; enddo
          if( ranks_local%west /= mpi_undefined ) then
             stat = cudaStreamSynchronize(comm_stream)
             fwest(:,:,2) = bufsnd1(:,:)
          else
             call mpi_irecv(bufrcv2,msize,mpi_real8,ranks%west,1,cart2d%comm,mreq1(1),merr)
             stat = cudaStreamSynchronize(comm_stream)
             call mpi_isend(bufsnd1,msize,mpi_real8,ranks%west,0,cart2d%comm,mreq1(2),merr)
          endif
          !$cuf kernel do(2) <<<*, *, stream=comm_stream>>>
          do k=1,var1; do j=1,jx
             bufsnd2(j,k) = VLd(ix-1,j,k)
          enddo; enddo
          if( ranks_local%east /= mpi_undefined ) then
             stat = cudaStreamSynchronize(comm_stream)
             fwest(:,:,1) = bufsnd2(:,:)
          else
             call mpi_irecv(bufrcv1,msize,mpi_real8,ranks%east,0,cart2d%comm,mreq2(1),merr)
             stat = cudaStreamSynchronize(comm_stream)
             call mpi_isend(bufsnd2,msize,mpi_real8,ranks%east,1,cart2d%comm,mreq2(2),merr)
          endif

          call mpi_win_unlock_all(mwin1,merr)
          call mpi_barrier(comm_local,merr)  ! local barrier

          if( ranks_local%west /= mpi_undefined ) then
             bufrcv2(:,:) = fptr1(:,:,1)
             !$cuf kernel do(2) <<<*, *, stream=comm_stream>>>
             do k=1,var1; do j=1,jx
                VLd(1,j,k) = bufrcv2(j,k)
             enddo; enddo
          else
             call mpi_waitall(2,mreq1,mpi_statuses_ignore,merr)
             if( ranks%west /= mpi_proc_null ) then
                !$cuf kernel do(2) <<<*, *, stream=comm_stream>>>
                do k=1,var1; do j=1,jx
                   VLd(1,j,k) = bufrcv2(j,k)
                enddo; enddo
             endif
          endif
          if( ranks_local%east /= mpi_undefined ) then
             bufrcv1(:,:) = fptr1(:,:,2)
             !$cuf kernel do(2) <<<*, *, stream=comm_stream>>>
             do k=1,var1; do j=1,jx
                VRd(ix-1,j,k) = bufrcv1(j,k)
             enddo; enddo
          else
             call mpi_waitall(2,mreq2,mpi_statuses_ignore,merr)
             if( ranks%east /= mpi_proc_null ) then
                !$cuf kernel do(2) <<<*, *, stream=comm_stream>>>
                do k=1,var1; do j=1,jx
                   VRd(ix-1,j,k) = bufrcv1(j,k)
                enddo; enddo
             endif
          endif

       end select
       ! MPI mode switch

       stat = cudaStreamSynchronize(comm_stream)
       deallocate( bufsnd1, bufrcv1 )
       deallocate( bufsnd2, bufrcv2 )

    !----------------------------------------------------------
    case(2)  ! south <--> north

       allocate( bufsnd1(ix,var1), bufrcv1(ix,var1) )
       allocate( bufsnd2(ix,var1), bufrcv2(ix,var1) )
       msize  = ix*var1

       ! MPI mode switch
       select case(mpi_mode(2))
       case(0)  ! no MPI

          ! periodic
          if( ranks%south /= mpi_proc_null ) then
             !$cuf kernel do(2) <<<*, *, stream=comm_stream>>>
             do k=1,var1; do i=1,ix
                VRd(i,jx-1,k) = VRd(i,   1,k)
                VLd(i,   1,k) = VLd(i,jx-1,k)
             enddo; enddo
          endif

       case(1)  ! MPI-1

          ! nonblocking communication (mreq1)
          call mpi_irecv(bufrcv1,msize,mpi_real8,ranks%north,0,cart2d%comm,mreq1(1),merr)
          !$cuf kernel do(2) <<<*, *, stream=comm_stream>>>
          do k=1,var1; do i=1,ix
             bufsnd1(i,k) = VRd(i,1,k)
          enddo; enddo
          stat = cudaStreamSynchronize(comm_stream)
          call mpi_isend(bufsnd1,msize,mpi_real8,ranks%south,0,cart2d%comm,mreq1(2),merr)
          ! nonblocking communication (mreq2)
          call mpi_irecv(bufrcv2,msize,mpi_real8,ranks%south,1,cart2d%comm,mreq2(1),merr)
          !$cuf kernel do(2) <<<*, *, stream=comm_stream>>>
          do k=1,var1; do i=1,ix
             bufsnd2(i,k) = VLd(i,jx-1,k)
          enddo; enddo
          stat = cudaStreamSynchronize(comm_stream)
          call mpi_isend(bufsnd2,msize,mpi_real8,ranks%north,1,cart2d%comm,mreq2(2),merr)

          call mpi_waitall(2,mreq1,mpi_statuses_ignore,merr)
          if( ranks%north /= mpi_proc_null ) then
             !$cuf kernel do(2) <<<*, *, stream=comm_stream>>>
             do k=1,var1; do i=1,ix
                VRd(i,jx-1,k) = bufrcv1(i,k)
             enddo; enddo
          endif
          call mpi_waitall(2,mreq2,mpi_statuses_ignore,merr)
          if( ranks%south /= mpi_proc_null ) then
             !$cuf kernel do(2) <<<*, *, stream=comm_stream>>>
             do k=1,var1; do i=1,ix
                VLd(i,1,k) = bufrcv2(i,k)
             enddo; enddo
          endif

       case(3)  ! MPI-3

          call mpi_win_lock_all(0,mwin2,merr)
          !$cuf kernel do(2) <<<*, *, stream=comm_stream>>>
          do k=1,var1; do i=1,ix
             bufsnd1(i,k) = VRd(i,1,k)
          enddo; enddo
          if( ranks_local%south /= mpi_undefined ) then
             stat = cudaStreamSynchronize(comm_stream)
             fsouth(:,:,2) = bufsnd1(:,:)
          else
             call mpi_irecv(bufrcv2,msize,mpi_real8,ranks%south,1,cart2d%comm,mreq1(1),merr)
             stat = cudaStreamSynchronize(comm_stream)
             call mpi_isend(bufsnd1,msize,mpi_real8,ranks%south,0,cart2d%comm,mreq1(2),merr)
          endif
          !$cuf kernel do(2) <<<*, *, stream=comm_stream>>>
          do k=1,var1; do i=1,ix
             bufsnd2(i,k) = VLd(i,jx-1,k)
          enddo; enddo
          if( ranks_local%north /= mpi_undefined ) then
             stat = cudaStreamSynchronize(comm_stream)
             fnorth(:,:,1) = bufsnd2(:,:)
          else
             call mpi_irecv(bufrcv1,msize,mpi_real8,ranks%north,0,cart2d%comm,mreq2(1),merr)
             stat = cudaStreamSynchronize(comm_stream)
             call mpi_isend(bufsnd2,msize,mpi_real8,ranks%north,1,cart2d%comm,mreq2(2),merr)
          endif

          call mpi_win_unlock_all(mwin2,merr)
          call mpi_barrier(comm_local,merr)  ! local barrier

          if( ranks_local%south /= mpi_undefined ) then
             bufrcv2(:,:) = fptr2(:,:,1)
             !$cuf kernel do(2) <<<*, *, stream=comm_stream>>>
             do k=1,var1; do i=1,ix
                VLd(i,1,k) = bufrcv2(i,k)
             enddo; enddo
          else
             call mpi_waitall(2,mreq1,mpi_statuses_ignore,merr)
             if( ranks%south /= mpi_proc_null ) then
                !$cuf kernel do(2) <<<*, *, stream=comm_stream>>>
                do k=1,var1; do i=1,ix
                   VLd(i,1,k) = bufrcv2(i,k)
                enddo; enddo
             endif
          endif
          if( ranks_local%north /= mpi_undefined ) then
             bufrcv1(:,:) = fptr2(:,:,2)
             !$cuf kernel do(2) <<<*, *, stream=comm_stream>>>
             do k=1,var1; do i=1,ix
                VRd(i,jx-1,k) = bufrcv1(i,k)
             enddo; enddo
          else
             call mpi_waitall(2,mreq2,mpi_statuses_ignore,merr)
             if( ranks%north /= mpi_proc_null ) then
                !$cuf kernel do(2) <<<*, *, stream=comm_stream>>>
                do k=1,var1; do i=1,ix
                      VRd(i,jx-1,k) = bufrcv1(i,k)
                enddo; enddo
             endif
          endif

       end select
       ! MPI mode switch

       stat = cudaStreamSynchronize(comm_stream)
       deallocate( bufsnd1, bufrcv1 )
       deallocate( bufsnd2, bufrcv2 )

    end select

  end subroutine parallel_exchange2

end module parallel
